Bug-finding tools have been an active area of research for almost as long as computer programs have existed. 
Intriguing techniques such as abstract interpretation, fuzzing, and symbolic execution with SAT solving have been proposed and developed.
But evaluation has been a problem, as  ground truth is in extremely short supply.
Vulnerability corpora exist [cite SAMATE] but they are of limited utility and quantity.
These corpora fall into two categories: historic and synthetic.
Corpora built from historic vulnerabilities such as [cite ours and others] contain too few examples to be of much use.
These are closest to what we would want to have since the bug is embedded in real code and are often well annotated with precise information about where the bug manifests itself.
However, given the pricetag of a new, exploitable bug (between 100 and 500K?. Cite?), these corpora are unlikely to swell quickly.
The author's own experience creating such a corpus was that it is a difficult and lengthy process; a corpus of only thirteen very well annotated bugs with triggering inpus took about six months to construct. 
And, while synthetic code stocked with bugs, auto-generated by scripts, can provide large numbers of diverse examples, each is only a tiny program and the constructions are often considered oddball and unrepresentative of real code.

In practice, a vulnerability discovery tool is typically evaluated by running it and seeing what it finds. 
Thus, one technique is judged superior if it finds more bugs than another.
While this state of affairs is perfectly understandable, given the scarcity of ground truth, it is an obstacle to science and progress in vulnerability discovery.
There is currently no way to measure fundamental figures of merit such as miss and false alarm rate for a bug finding tool.

We propose the following requirements for bugs in a vulnerbility corpus, if it is to be useful for research, development, and evaluation.
Bugs must be
\begin{enumerate}
\item Cheap and plentiful
\item Span the execution lifetime of a program, i.e., deep as well as shallow
\item Embedded in representative control and data flow
\item Come with an input that serves as an existence proof 
\item Manifest for a very small fraction of possible inputs
\end {enumerate}
The first requirement, if we can meet it, is highly desirable since it enables hill climbing and continued evaluation.
Corpora are more valuable if they are essentially disposable. 
The second and third of these requirements are versions of ``the bugs must be realistic''.
The fourth means the bug is real and serious, and is a precondition for determining exploitability. 
The fifth is crucial; conversely, if the bug manifests for all or a large fraction of inputs it is trivially discoverable,

The approach we propose is to create a synthetic vulnerability via a few judicious and automated edits to the source code of a real program.
We will detail and give results for an implementation of this approach that satisfies all of the above requirements.
We call this implementation LAVA for Lincoln Automated Vulnerability Application.
A serious bug such as a buffer overflow can be injected by LAVA into a program of X LOC in about a minute, and for programs of this size LAVA can inject  Y thousand such bugs.
LAVA bugs manifest all along the execution trace, in all parts of the program, and make use of mostly completely normal data flow.
By construction, a LAVA bug comes with an input that triggers it, and no other input can have this effect upon the program.

This paper is organized as follows. 
[Do we want to do this?]
